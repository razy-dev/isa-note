= 1. 데이터베이스 개요
include::../style/style.adoc[]

== 1.1. 데이터베이스 개념

=== 데이터베이스 정의
한 조직의 여러 응용시스템이 공용(Shared)하기 위해 최소 중복으로 통합(Integrated), 저장(Store)된 운영(Operational) 데이터의 집합

. *``통``합 데이터*(Integrated) : 최소의 중복 / 통제된 중복
. *``저``장 데이터*(Stored) : 컴퓨터가 접근 가능한 매체에 저장
. *``운``영 데이터*(Operational) : 조직 운영에 필요한 필수적인 데이터
. *``공``유 데이터*(Shared) : 여러 응용 프로그램이 공동으로 사용

== 1.2. DBMS 발전 배경
=== 파일시스템의 문제점
. 데이터 종속성(Data Dependency)
* 응용 프로그램과 데이터간의 상호 의존(종속)

. 데이터 중복성(Data Redundancy)
* ``일``관성 :
* ``보``안성 :
* ``경``제성 :
* ``무``결성 :

== 1.3. DBMS 정의
응용프로그램과 데이터의 중재자로서 모든 응용프로그램들이 데이터베이스를 공용할 수 있도록 관리해주는 소프트웨어 시스템

=== 데이터베이스 기능
* **정의**기능(Definition)
* **조작**기능(Manipulation:CRUD)
* **제어**기능(Control)

== 1.4. 데이터베이스 시스템
데이터를 DB로 저장하고 관리해서 필요한 정보를 생성하는 컴퓨터 중심의 시스템

=== 데이터 언어(Data Language)
* 데이터 정의어(DDL)
* 데이터 조작어(DML)
* 데이터 제어어(DCL)

== 1.5. 3단계 데이터베이스 구조
사용자의 응용과 물리적 데이터베이스의 분리

[cols="^2,^1,^2,<5"]
|===
| 단계 | 갯수 | 관점 | 목적
| 외부 Schema | N 개 | 사용자관점  | 사용자 View. 특정 사용자 그룹이 관심을 갖는 부분을 보여주고, 나머지는 은폐
4+| 논리적 Data 독립성 확보
| 개념 Schema | 1 개 | 전사 관점   | 전체 사용자를 위한 데이터베이스의 구조를 기술
4+| 물리적 Data 독립성 확보
| 내부 Schema | 1 개 | 장치 관점   | 물리적 데이터 모델을 사용. 데이터 저장 구조의 세부 사항과 데이터베이스에 대한 접근 경로를 기술
|===

== 1.6. 데이터아키텍쳐 및 데이터베이스 관리
=== 1.6.1. 데이터아키텍쳐 및 데이터베이스 구축 방법론
=== 1.6.2. 공공데이터 품질관리
==== 데이터 품질 관리
. 계획단계 품질관리
. 구축단계 품질관리 `감리`
. 운영단계 품질관리 `감리`
. 활용단계 품질관리

==== 데이터 품질 진단 및 개선
. 진단대상 정의
. 품질진단 실시 `감리`
. 진단결과 분석 `감리`
. 개선계획 수립
. 개선 수행 `감리`
. 품질 통제

=== 1.6.3. 공공기관의 데이터베이스 표준화 관리
=== 1.6.4. 데이터 품질 관리 대상 및 품질 지표
==== 데이터 품질 관리 대상
[cols="^4,<6"]
|===
| 관리 대상 ^| 내용
| 데이터 값 <|
* 데이터 현상적 값 +
* 데이터 구조적 값 +
| 데이터 구조 <|
* 각 단계별 데이터 구조 +
* 각 조직 단위별 데이터 구조 +
| 데이터 관리 프로세스 <|
* 데이터 정의 프로세스 +
* 데이터 변경 프로세스 +
* 데이터 평가 프로세스 +
|===

==== 데이터 품질 지표
[cols="^2,^2,<3,<3"]
|===
| 구분 | 지표 ^| 설명 ^| 세부 지표
.2+| *유효성*
| *정확성* <| 실세계를 정확히 반영         <| 사실성, 적합성, 필수성, 연관성
| *일관성* <| 동일 데이터간 불일치 미존재  <| 정합성, 일치성, 무결성

.4+| *활용성*
| *유용성* <| 요구되는 데이터 충족              <| 충분성, 유연성, 사용성, 추적성
| *접근성* <| 원하는 데이터를 손쉽게 이용       <| -
| *적시성* <| 최신성 유지                       <| -
| *보안성* <| 내외부 요인으로부터 데이터 보호   <| 보호성, 책임성, 안정성
|===

==== 데이터 품질 관리 프레임워크
==== 데이터 품질 관리 프로세스

== 1.7. 데이터베이스 저장 장치
=== 1.7.1 데이터를 디스크에 물리적으로 저장하는 방법
** 순차 파일(Sequential File)
** 인덱스 파일(Indexed File)
** 해싱 파일(Hashing File)
** B-Tree

=== 1.7.2 자기 디스크 구조
==== 디스크 접근 시간
** 탐색시간
** 회전지연시간
** 전송지연시간

==== Block(Page) 구조
디스크와 주기억장치간 데이터 전송은 Block(Page) 단위로 수행

* `TODO` 이미지 추가

== 1.8. 데이터베이스 접근
[%noheader]
|===
| Slot              |
| Sub-Block         |
| Inter Record Gap  | 레코드와 레코드 사이의 갭.(레코드 구분)
| Inter Block Gap   | 블록과 블록사이의 갭. (다음 블록을 읽을 때 읽기위한 속도을 회복하기 위해 사용)
| Blocking Factor   | 한 **block**에 저장 할 수 있는 *record*(*tuple*, *row*)의 수
|===

==== Blocking Factor 계산 예제

`Problem`

*Block 단위로 저장한 disk에서*

* 20,000 bytes/track 을 담을 수 있다.
* Subblock, interblock gap은 300 bytes/block 정도이다.

하나의 파일이 100 bytes인 record들을 저장하고 싶을 때, blocking factor가 10 또는 60 인 경우에 몇 개의 record들을 저장할 수 있는가?

`Solve`

*Blocking factor가 10인 경우*

* 1 block의 크기 = 10개 * (100 bytes 짜리 record) + 300
* 20,000 bytes에는 20,000 / (10*100 + 300) = 15 blocks = 150 records 가 들어갈 수 있다.

*Blocking factor가 60인 경우,*

* 1 block의 크기 = 60개 * (100 bytes 짜리 record) + 300
* 20,000 bytes / (60*100 + 300) = 3 block = 180 records 가 들어갈 수 있다.

== 1.9. 파일조작 기본 방식
* 순차 방법
** 엔트리 순차 파일
** 키 순차 파일
* 인덱스 방법
** 인덱스된 파일
*** ISAM
*** vSAM
** 다중키 파일
*** 다중리스트 파일
*** 역 파일
* 해싱 방법
** 직접 파일
*** Closed Hash
*** Open Hash

=== 1.9.1. 순차 방법
=== 1.9.2. 인덱스 방법
==== 인덱스 분류
* 기본키 여부에 따른 분류
** 기본 인덱스
** 보조 인덱스

* 인덱스 엔트리 순서에 따른 분류
** 집중 인덱스
** 비 집중 인덱스

* 엔트리 맵핑 여부에 따른 분류
** 밀집 인덱스
** 희소 인덱스

* 인덱스를 구성하는 구조나 특징에 따른 분류
** 트리기반 인덱스
** 비트맵 인덱스
** 비트맵조인 인덱스
** 함수기반 인덱스(FBI)

==== 다단계 인덱스
==== 다중키 파일

=== 1.9.3. 해시 방법
==== 용어
* 해싱 함수(hashing function)/사상함수(mapping function)
** 키 값으로부터 레코드의 물리적 주소로 사상시키는 사상 함수
* 슬롯(Slot)
** 한 개의 레코드를 저장 할 수 있는 공간
* 버켓(Bucket)
** Bucket 하나의 주소를 가지면서 하나 이상의 레코드를 저장할 수 있는 파일의 한 구역
** 크기는 같은 주소에 포함될 수 있는 레코드 수
** 여러 개의 슬롯으로 구성
* 충돌(Collision)
** 서로 다른 두개의 키 값이 동일한 주소같은 버킷로 산출된 현상
* 동거자(Synonym)
**  동일한 주소로 산출된 두 키 값
* 오버플로우(Overflow)
** 저장공간(Slot)이 없는 버켓에 레코드가 저장되도록 해싱되는 현상
* 적재밀도
** 실제 사용중인 키 값 갯수버킷 개수슬롯 개수

==== 해싱 충돌 해결
===== 정적 해시 (Bucket Size 가 고정되었을 경우)
image::정적해시.png[]

* *개방 주소*
** 해시 충돌이 일어나면 다른 버킷에 데이터를 저장
* *체이닝*
** 해시 충돌이 발생하면 키에 해당하는 데이터들을 연결(Linked List)
* *다중 해싱*
** 해시 충돌시 다른 해시함수를 한 번더 적용

===== 확장성(동적) 해시
해싱 충돌 문제점 해결

image::확장해시.png[]
image::확장해시 확장.png[]

* https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=skyjjw79&logNo=220875535595

== 1.10. Tree
=== 1.10.1. Tree 개요
==== 이진 탐색 트리

=== 1.10.2. B Tree
[cols="^2,<4,<4"]
|===
| 구분    ^| B Tree ^| B+ Tree
| 접근성
| * Leaf에 가기전에 값을 찾을 수 있다
| * 레코드의 위치는 Leaf 노드에서만 파악된다 +
* 순차검색(범위검색)이 유리하다
| 중복성
| * 탐색 키의 중복성이 없다
| * Index Set 과 Sequence Set 에 중복된다
| 복잡성
| * Leaf 가 아닌 노드 Size 가 더 크다 +
* Index 에 대한 저장공간 관리가 보잡하다 +
* 삽입, 삭제가 복잡하다
| * 모든 노드의 크기가 같다 +
* 삭제가 쉽다 +
(삭제될 노드가 항상 Leaf 에 존재한다)
|===

* `TODO` image

=== 1.10.3. B-Tree 순회연산
==== B-Tree 전위순회
image::b-tree-전위순회.png[]
* `ROOT` 에서 시작. 왼쪽 빗변을 따라 진행
* 오른쪽 `마지막 노드` **전위순회**로 끝

==== B-Tree 중위순회
image::b-tree-중위순회.png[]
* 왼쪽 `마지막 노드` **중위순회**로 시작
* 오른쪽 `마지막 노드` **중위순회**로 끝

==== B-Tree 후위순회
image::b-tree-후위순회.png[]
* 왼쪽 `마지막 노드` **후위순회**로 시작
* 오른쪽 빗변 **역순**으로 끝

=== 1.10.4. B-Tree 삽입 연산

* https://velog.io/@emplam27/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EA%B7%B8%EB%A6%BC%EC%9C%BC%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-B-Tree
